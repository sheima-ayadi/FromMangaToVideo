{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chemin actuel : c:\\Users\\cheim\\ml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Chemin actuel :\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python-headless in c:\\users\\cheim\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\cheim\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\cheim\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from opencv-python-headless) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python-headless opencv-contrib-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdf2image in c:\\users\\cheim\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.17.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\cheim\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pdf2image) (11.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pdf2image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction des images depuis les PDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [04:15<00:00, 25.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prétraitement des images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 530/530 [00:21<00:00, 24.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction du texte via OCR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 530/530 [00:55<00:00,  9.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline terminé. Les annotations sont sauvegardées dans annotations.json.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pdf2image import convert_from_path\n",
    "import cv2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Chemins des dossiers\n",
    "PDF_FOLDER = \"manga_dataset\"  # Dossier contenant les fichiers PDF\n",
    "OUTPUT_FOLDER = \"extracted_images\"  # Dossier pour les images extraites\n",
    "PREPROCESSED_FOLDER = \"preprocessed_images\"  # Dossier pour les images prétraitées\n",
    "ANNOTATION_FILE = \"annotations.json\"  # Fichier JSON pour stocker les annotations\n",
    "\n",
    "# Créer les dossiers si nécessaires\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "os.makedirs(PREPROCESSED_FOLDER, exist_ok=True)\n",
    "\n",
    "# 1. Extraction des images depuis les PDF\n",
    "def extract_images_from_pdfs(pdf_folder, output_folder):\n",
    "    print(\"Extraction des images depuis les PDF...\")\n",
    "    for pdf_file in tqdm(os.listdir(pdf_folder)):\n",
    "        if pdf_file.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(pdf_folder, pdf_file)\n",
    "            images = convert_from_path(pdf_path)\n",
    "            for i, image in enumerate(images):\n",
    "                image_name = f\"{os.path.splitext(pdf_file)[0]}_page_{i+1}.jpg\"\n",
    "                image_path = os.path.join(output_folder, image_name)\n",
    "                image.save(image_path, \"JPEG\")\n",
    "\n",
    "# 2. Prétraitement des images\n",
    "def preprocess_images(input_folder, output_folder):\n",
    "    print(\"Prétraitement des images...\")\n",
    "    for image_file in tqdm(os.listdir(input_folder)):\n",
    "        if image_file.endswith(\".jpg\"):\n",
    "            image_path = os.path.join(input_folder, image_file)\n",
    "            image = cv2.imread(image_path)\n",
    "            \n",
    "            # Redimensionner l'image\n",
    "            resized_image = cv2.resize(image, (256, 256))\n",
    "            \n",
    "            # Convertir en niveaux de gris\n",
    "            gray_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Sauvegarder l'image prétraitée\n",
    "            output_path = os.path.join(output_folder, image_file)\n",
    "            cv2.imwrite(output_path, gray_image)\n",
    "\n",
    "# 3. Extraction du texte avec OCR\n",
    "def extract_text_with_ocr(input_folder):\n",
    "    print(\"Extraction du texte via OCR...\")\n",
    "    annotations = []\n",
    "    for image_file in tqdm(os.listdir(input_folder)):\n",
    "        if image_file.endswith(\".jpg\"):\n",
    "            image_path = os.path.join(input_folder, image_file)\n",
    "            image = Image.open(image_path)\n",
    "            \n",
    "            # Extraire le texte avec Tesseract OCR\n",
    "            text = pytesseract.image_to_string(image, lang=\"eng\")  # Ajustez \"lang\" selon la langue\n",
    "            annotations.append({\"image\": image_file, \"text\": text})\n",
    "    \n",
    "    # Sauvegarder les annotations dans un fichier JSON\n",
    "    with open(ANNOTATION_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(annotations, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "# 4. Pipeline complet\n",
    "def main():\n",
    "    # Étape 1 : Extraire les images des PDF\n",
    "    extract_images_from_pdfs(PDF_FOLDER, OUTPUT_FOLDER)\n",
    "    \n",
    "    # Étape 2 : Prétraiter les images\n",
    "    preprocess_images(OUTPUT_FOLDER, PREPROCESSED_FOLDER)\n",
    "    \n",
    "    # Étape 3 : Extraire le texte avec OCR\n",
    "    extract_text_with_ocr(PREPROCESSED_FOLDER)\n",
    "    \n",
    "    print(f\"Pipeline terminé. Les annotations sont sauvegardées dans {ANNOTATION_FILE}.\")\n",
    "\n",
    "# Lancer le script\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytesseract\n",
      "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\cheim\\appdata\\roaming\\python\\python313\\site-packages (from pytesseract) (24.2)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\cheim\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pytesseract) (11.0.0)\n",
      "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: pytesseract\n",
      "Successfully installed pytesseract-0.3.13\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytesseract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.0-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\cheim\\appdata\\roaming\\python\\python313\\site-packages (from tqdm) (0.4.6)\n",
      "Downloading tqdm-4.67.0-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prétraitement des images déjà extracté du pdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prétraitement des images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 40.85it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 39.33it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 38.01it/s]\n",
      "100%|██████████| 54/54 [00:00<00:00, 77.76it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 79.75it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 85.88it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 77.51it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 76.77it/s]\n",
      "100%|██████████| 54/54 [00:00<00:00, 74.47it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 69.05it/s]\n",
      "100%|██████████| 46/46 [00:00<00:00, 74.69it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 66.83it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 52.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction du texte via OCR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00, 10.42it/s]\n",
      "100%|██████████| 16/16 [00:01<00:00, 10.74it/s]\n",
      "100%|██████████| 15/15 [00:01<00:00, 10.43it/s]\n",
      "100%|██████████| 54/54 [00:05<00:00, 10.55it/s]\n",
      "100%|██████████| 23/23 [00:02<00:00, 10.41it/s]\n",
      "100%|██████████| 25/25 [00:02<00:00, 10.19it/s]\n",
      "100%|██████████| 22/22 [00:02<00:00,  9.79it/s]\n",
      "100%|██████████| 20/20 [00:02<00:00,  9.93it/s]\n",
      "100%|██████████| 54/54 [00:05<00:00, 10.09it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.41it/s]\n",
      "100%|██████████| 46/46 [00:04<00:00, 10.47it/s]\n",
      "100%|██████████| 19/19 [00:01<00:00, 10.30it/s]\n",
      "100%|██████████| 16/16 [00:01<00:00, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline terminé. Les annotations sont sauvegardées dans annotations.json.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Chemins des dossiers\n",
    "MANGA_FOLDER = \"manga_dataset\"  # Racine contenant tous les mangas et leurs chapitres\n",
    "PREPROCESSED_FOLDER = \"preprocessed_images\"  # Dossier pour les images prétraitées\n",
    "ANNOTATION_FILE = \"annotations.json\"  # Fichier JSON pour stocker les annotations\n",
    "\n",
    "# Créer les dossiers si nécessaires\n",
    "os.makedirs(PREPROCESSED_FOLDER, exist_ok=True)\n",
    "\n",
    "# 1. Prétraitement des images\n",
    "def preprocess_images(input_folder, output_folder):\n",
    "    print(\"Prétraitement des images...\")\n",
    "    for manga_name in os.listdir(input_folder):\n",
    "        manga_path = os.path.join(input_folder, manga_name)\n",
    "        if os.path.isdir(manga_path):  # Vérifie si c'est un dossier\n",
    "            for chapter_name in os.listdir(manga_path):\n",
    "                chapter_path = os.path.join(manga_path, chapter_name)\n",
    "                if os.path.isdir(chapter_path):  # Vérifie si c'est un dossier\n",
    "                    for image_file in tqdm(os.listdir(chapter_path)):\n",
    "                        if image_file.endswith(\".jpg\"):\n",
    "                            image_path = os.path.join(chapter_path, image_file)\n",
    "                            image = cv2.imread(image_path)\n",
    "                            \n",
    "                            # Redimensionner l'image\n",
    "                            resized_image = cv2.resize(image, (256, 256))\n",
    "                            \n",
    "                            # Convertir en niveaux de gris\n",
    "                            gray_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "                            \n",
    "                            # Conserver la structure des dossiers dans l'output\n",
    "                            relative_path = os.path.relpath(chapter_path, input_folder)\n",
    "                            output_dir = os.path.join(output_folder, relative_path)\n",
    "                            os.makedirs(output_dir, exist_ok=True)\n",
    "                            output_path = os.path.join(output_dir, image_file)\n",
    "                            cv2.imwrite(output_path, gray_image)\n",
    "\n",
    "# 2. Extraction du texte avec OCR\n",
    "def extract_text_with_ocr(input_folder):\n",
    "    print(\"Extraction du texte via OCR...\")\n",
    "    annotations = []\n",
    "    for manga_name in os.listdir(input_folder):\n",
    "        manga_path = os.path.join(input_folder, manga_name)\n",
    "        if os.path.isdir(manga_path):  # Vérifie si c'est un dossier\n",
    "            for chapter_name in os.listdir(manga_path):\n",
    "                chapter_path = os.path.join(manga_path, chapter_name)\n",
    "                if os.path.isdir(chapter_path):  # Vérifie si c'est un dossier\n",
    "                    for image_file in tqdm(os.listdir(chapter_path)):\n",
    "                        if image_file.endswith(\".jpg\"):\n",
    "                            image_path = os.path.join(chapter_path, image_file)\n",
    "                            image = Image.open(image_path)\n",
    "                            \n",
    "                            # Extraire le texte avec Tesseract OCR\n",
    "                            text = pytesseract.image_to_string(image, lang=\"eng\")  # Ajustez \"lang\" selon la langue\n",
    "                            \n",
    "                            # Conserver la hiérarchie des dossiers dans l'annotation\n",
    "                            relative_path = os.path.relpath(chapter_path, input_folder)\n",
    "                            annotations.append({\n",
    "                                \"manga\": manga_name,\n",
    "                                \"chapter\": chapter_name,\n",
    "                                \"image\": os.path.join(relative_path, image_file),\n",
    "                                \"text\": text\n",
    "                            })\n",
    "    \n",
    "    # Sauvegarder les annotations dans un fichier JSON\n",
    "    with open(ANNOTATION_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(annotations, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "# 3. Pipeline complet\n",
    "def main():\n",
    "    # Étape 1 : Prétraiter les images\n",
    "    preprocess_images(MANGA_FOLDER, PREPROCESSED_FOLDER)\n",
    "    \n",
    "    # Étape 2 : Extraire le texte avec OCR\n",
    "    extract_text_with_ocr(PREPROCESSED_FOLDER)\n",
    "    \n",
    "    print(f\"Pipeline terminé. Les annotations sont sauvegardées dans {ANNOTATION_FILE}.\")\n",
    "\n",
    "# Lancer le script\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from pytesseract import image_to_string\n",
    "\n",
    "IMAGE_FOLDER = \"manga_dataset\"\n",
    "OUTPUT_DATA = []\n",
    "\n",
    "def extract_text(image_path):\n",
    "    try:\n",
    "        return image_to_string(Image.open(image_path), lang=\"eng\")  # Changez 'eng' si le texte est dans une autre langue\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'extraction de texte pour {image_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "for manga in os.listdir(IMAGE_FOLDER):\n",
    "    manga_path = os.path.join(IMAGE_FOLDER, manga)\n",
    "    if os.path.isdir(manga_path):\n",
    "        for chapter in os.listdir(manga_path):\n",
    "            chapter_path = os.path.join(manga_path, chapter)\n",
    "            if os.path.isdir(chapter_path):\n",
    "                for image_file in os.listdir(chapter_path):\n",
    "                    image_path = os.path.join(chapter_path, image_file)\n",
    "                    if image_file.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                        text = extract_text(image_path)\n",
    "                        OUTPUT_DATA.append({\n",
    "                            \"manga\": manga,\n",
    "                            \"chapter\": chapter,\n",
    "                            \"image\": os.path.relpath(image_path),\n",
    "                            \"text\": text.strip()\n",
    "                        })\n",
    "\n",
    "# Exportez les résultats au format JSON si nécessaire\n",
    "import json\n",
    "with open(\"output.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(OUTPUT_DATA, f, ensure_ascii=False, indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
